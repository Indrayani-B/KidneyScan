{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc85f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df21307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\asdaw\\\\Desktop\\\\Projects\\\\KidneyScan\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c61373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517ea066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\asdaw\\\\Desktop\\\\Projects\\\\KidneyScan'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eebc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    history_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_image_size: list\n",
    "    params_is_augmentation: bool\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe03902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f714b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        params_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(\n",
    "            self.config.data_ingestion.unzip_dir,\n",
    "             \"kidney-ct-scan-image\"\n",
    "        )\n",
    "        \n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "        \n",
    "        training_config = TrainingConfig(\n",
    "            root_dir = Path(training.root_dir),\n",
    "            trained_model_path = Path(training.trained_model_path),\n",
    "            history_path = Path(training.history_path),\n",
    "            updated_base_model_path = Path(params_base_model.updated_base_model_path),\n",
    "            training_data = Path(training_data),\n",
    "            params_epochs = params.EPOCHS,\n",
    "            params_batch_size = params.BATCH_SIZE,\n",
    "            params_image_size = params.IMAGE_SIZE,\n",
    "            params_is_augmentation = params.AUGMENTATION\n",
    "        )\n",
    "        \n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b1368fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1425c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    @staticmethod\n",
    "    def save_history(path: Path, history: dict):\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "        # Convert numpy types to native Python types\n",
    "        cleaned_history = {\n",
    "            key: [float(value) for value in values]\n",
    "            for key, values in history.items()\n",
    "        }\n",
    "    \n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(cleaned_history, f, indent=4)\n",
    "\n",
    "    \n",
    "    def get_callbacks(self):\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.2,\n",
    "            patience=3,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "        \n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=self.config.trained_model_path,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True\n",
    "        )\n",
    "        \n",
    "        return [early_stopping, reduce_lr, checkpoint]\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        self.steps_per_epoch = math.ceil(\n",
    "        self.train_generator.samples / self.train_generator.batch_size\n",
    "        )\n",
    "        self.validation_steps = math.ceil(\n",
    "            self.valid_generator.samples / self.valid_generator.batch_size\n",
    "        )\n",
    "        callbacks = self.get_callbacks()\n",
    "\n",
    "        history = self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,  # upper bound only\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_data=self.valid_generator,\n",
    "            validation_steps=self.validation_steps,\n",
    "            callbacks=callbacks\n",
    "        )    \n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n",
    "\n",
    "        self.save_history(\n",
    "            path=self.config.history_path,\n",
    "            history=history.history\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a3bcb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-26 18:45:24,384: INFO: common]: yaml file: C:\\Users\\asdaw\\Desktop\\Projects\\KidneyScan\\config\\config.yaml loaded successfully]\n",
      "[2025-12-26 18:45:24,386: INFO: common]: yaml file: C:\\Users\\asdaw\\Desktop\\Projects\\KidneyScan\\params.yaml loaded successfully]\n",
      "[2025-12-26 18:45:24,388: INFO: common]: created directory at: artificats]\n",
      "[2025-12-26 18:45:24,389: INFO: common]: created directory at: artifacts\\training]\n",
      "Found 93 images belonging to 2 classes.\n",
      "Found 372 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "24/24 [==============================] - 35s 1s/step - loss: 9.3010 - accuracy: 0.6075 - val_loss: 1.4429 - val_accuracy: 0.8817 - lr: 0.0100\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 5.9662 - accuracy: 0.6882 - val_loss: 9.2679 - val_accuracy: 0.5054 - lr: 0.0100\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 4.5553 - accuracy: 0.7473 - val_loss: 2.6089 - val_accuracy: 0.5269 - lr: 0.0100\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 2.5800 - accuracy: 0.7930 - val_loss: 3.1636 - val_accuracy: 0.5484 - lr: 0.0100\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 39s 2s/step - loss: 0.8394 - accuracy: 0.8495 - val_loss: 0.6657 - val_accuracy: 0.8172 - lr: 0.0020\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.6079 - accuracy: 0.8737 - val_loss: 0.2778 - val_accuracy: 0.8925 - lr: 0.0020\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.2930 - accuracy: 0.9274 - val_loss: 0.2152 - val_accuracy: 0.9355 - lr: 0.0020\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.2859 - accuracy: 0.9167 - val_loss: 0.1025 - val_accuracy: 0.9462 - lr: 0.0020\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.2931 - accuracy: 0.9113 - val_loss: 0.0557 - val_accuracy: 0.9570 - lr: 0.0020\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.1962 - accuracy: 0.9409 - val_loss: 0.1759 - val_accuracy: 0.9355 - lr: 0.0020\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.1421 - accuracy: 0.9435 - val_loss: 0.0638 - val_accuracy: 0.9570 - lr: 0.0020\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.1445 - accuracy: 0.9570 - val_loss: 0.0512 - val_accuracy: 0.9570 - lr: 0.0020\n",
      "Epoch 13/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.1008 - accuracy: 0.9677 - val_loss: 0.0110 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 14/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.1608 - accuracy: 0.9435 - val_loss: 0.0158 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 15/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.0936 - accuracy: 0.9677 - val_loss: 0.0054 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 16/30\n",
      "24/24 [==============================] - 43s 2s/step - loss: 0.0985 - accuracy: 0.9651 - val_loss: 0.0204 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 17/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.1090 - accuracy: 0.9731 - val_loss: 0.0062 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 18/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.1226 - accuracy: 0.9651 - val_loss: 0.0020 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 19/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.1013 - accuracy: 0.9677 - val_loss: 0.0015 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 20/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0019 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 21/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.0566 - accuracy: 0.9785 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 22/30\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.0539 - accuracy: 0.9785 - val_loss: 0.0016 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 23/30\n",
      "24/24 [==============================] - 39s 2s/step - loss: 0.0895 - accuracy: 0.9812 - val_loss: 8.8696e-04 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 24/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.0913 - accuracy: 0.9624 - val_loss: 7.4956e-04 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 25/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.0654 - accuracy: 0.9758 - val_loss: 6.5974e-04 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 26/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.0707 - accuracy: 0.9731 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 27/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.0764 - accuracy: 0.9651 - val_loss: 5.1183e-04 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 28/30\n",
      "24/24 [==============================] - 39s 2s/step - loss: 0.0590 - accuracy: 0.9812 - val_loss: 0.0113 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 29/30\n",
      "24/24 [==============================] - 39s 2s/step - loss: 0.0339 - accuracy: 0.9892 - val_loss: 7.5281e-04 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 30/30\n",
      "24/24 [==============================] - 40s 2s/step - loss: 0.0485 - accuracy: 0.9919 - val_loss: 4.3906e-04 - val_accuracy: 1.0000 - lr: 0.0020\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "     \n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46cf67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidney",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
